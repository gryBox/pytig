{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/environment/pytig'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "import boto3\n",
    "from boto3.dynamodb.conditions import Key\n",
    "import os\n",
    "from google_images_download import google_images_download\n",
    "import glob\n",
    "import PIL\n",
    "import json\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "import textacy\n",
    "import en_core_web_sm\n",
    "\n",
    "# from custo import greedy_algorithm\n",
    "#import input_data_preprocessing.corpus_stats as c_stats\n",
    "\n",
    "textacy.spacier.doc_extensions.set_doc_extensions()\n",
    "#import code\n",
    "print(textacy.__version__)\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TIG Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prepare_meta_data as pmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/environment/pytig/data'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Requirements: A directory with unprocessed corresponding labeled images and text files. \n",
    "Example data. \n",
    "- photosynthesis\n",
    "    --text\n",
    "        file_name.txt\n",
    "        file_name1.txt\n",
    "    --images\n",
    "        file_name.png\n",
    "        file_name1.png\n",
    "\"\"\"\n",
    "def zip_to_metadata_dir(zip_url, data_dir_path)    \n",
    "    # Returns a zipped directory \n",
    "    zipfile = pmd.load.zip_from_url(zip_url)\n",
    "\n",
    "    # Write zip data to dir for preparing metadat files\n",
    "    zipfile.extractall(data_dir_path)\n",
    "    \n",
    "    return zipfile\n",
    "    \n",
    "    \n",
    "def modify_captions(txt_dir_path, lowercase=True, split_sents=False):\n",
    "    \"\"\"\n",
    "    Optional - Loads txt files into a spacy corpus and prepare captions data for algorithm.\n",
    "    Returns a dictionary with filename as key and caption list as value (caption is item in list )\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare Data for Algorithm\n",
    "    # # Lowercase and remove punctuation for labels and filenames\n",
    "    crps = pmd.load.txt_to_corpus(os.path.join(data_dir,'text'))\n",
    "    \n",
    "    return captions_dict\n",
    "\n",
    "\n",
    "    \n",
    "def captions_to_text():\n",
    "    \"\"\"\n",
    "    Warning: Overwrites original data. \n",
    "    \"\"\"\n",
    "    # Write new captions to txt files\n",
    "    pmd.write.corpus_to_text(crps)\n",
    "    return\n",
    "\n",
    "\n",
    "# Create Generic Filenames txt file\n",
    "file_name_lst = pmd.read.file_names_to_lsts()\n",
    "\n",
    "# Compare image filename list with \n",
    "    \n",
    "zip_url = \"https://github.com/gryBox/pytig-data/raw/master/photosynthesis_raw.zip\"\n",
    "data_dir_name = os.path.abspath('data')\n",
    "\n",
    "image_dir_name =  'image'\n",
    "text_dir_name =  \"text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data.s(source, destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/imageGen/AttnGAN/data/'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.path.join(os.path.expanduser(\"~\"), 'imageGen/AttnGAN/data/')\n",
    "print(os.path.exists(data_path))\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): github.com:443\n",
      "DEBUG:urllib3.connectionpool:https://github.com:443 \"GET /gryBox/pytig-data/raw/master/photosynthesis_raw.zip HTTP/1.1\" 302 147\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): raw.githubusercontent.com:443\n",
      "DEBUG:urllib3.connectionpool:https://raw.githubusercontent.com:443 \"GET /gryBox/pytig-data/master/photosynthesis_raw.zip HTTP/1.1\" 200 161727\n",
      "INFO:root:Input Corpus: Corpus(7 docs, 986 tokens)\n",
      "DEBUG:root:Finished calculating CorpusStats\n",
      "INFO:root:Shortest Doc - Number of tokens 24\n",
      "DEBUG:root:Finished - Maximizimizing number of captions per image\n",
      "INFO:root:MaximizeDocCaptions - Number of captions 8\n",
      "DEBUG:root:New doc in Corpus Resizing Image Caption 0\n",
      "DEBUG:root:Ideal caption length: 121\n",
      "DEBUG:root:Number of characters per captions: 0\n",
      "DEBUG:root:Number of characters per captions: 0\n",
      "DEBUG:root:Number of characters per captions: 0\n",
      "DEBUG:root:Number of characters per captions: 0\n",
      "DEBUG:root:Number of characters per captions: 0\n",
      "DEBUG:root:Number of characters per captions: 0\n",
      "DEBUG:root:Number of characters per captions: 0\n",
      "DEBUG:root:Number of characters per captions: 0\n",
      "DEBUG:root:Final Number of captions per image: 8\n",
      "DEBUG:root:New doc in Corpus Resizing Image Caption 1\n",
      "DEBUG:root:Finished - Maximizimizing number of captions per image\n",
      "INFO:root:MaximizeDocCaptions - Number of captions 8\n",
      "DEBUG:root:Final Number of captions per image: 8\n",
      "DEBUG:root:New doc in Corpus Resizing Image Caption 2\n",
      "DEBUG:root:Finished - Maximizimizing number of captions per image\n",
      "INFO:root:MaximizeDocCaptions - Number of captions 35\n",
      "DEBUG:root:Ideal caption length: 103\n",
      "DEBUG:root:Number of characters per captions: 95\n",
      "DEBUG:root:Number of characters per captions: 103\n",
      "DEBUG:root:Number of characters per captions: 115\n",
      "DEBUG:root:Number of characters per captions: 118\n",
      "DEBUG:root:Number of characters per captions: 111\n",
      "DEBUG:root:Number of characters per captions: 102\n",
      "DEBUG:root:Number of characters per captions: 120\n",
      "DEBUG:root:Number of characters per captions: 106\n",
      "DEBUG:root:Final Number of captions per image: 8\n",
      "DEBUG:root:New doc in Corpus Resizing Image Caption 3\n",
      "DEBUG:root:Finished - Maximizimizing number of captions per image\n",
      "INFO:root:MaximizeDocCaptions - Number of captions 14\n",
      "DEBUG:root:Ideal caption length: 44\n",
      "DEBUG:root:Number of characters per captions: 48\n",
      "DEBUG:root:Number of characters per captions: 32\n",
      "DEBUG:root:Number of characters per captions: 31\n",
      "DEBUG:root:Number of characters per captions: 43\n",
      "DEBUG:root:Number of characters per captions: 31\n",
      "DEBUG:root:Number of characters per captions: 21\n",
      "DEBUG:root:Number of characters per captions: 34\n",
      "DEBUG:root:Number of characters per captions: 41\n",
      "DEBUG:root:Final Number of captions per image: 8\n",
      "DEBUG:root:New doc in Corpus Resizing Image Caption 4\n",
      "DEBUG:root:Ideal caption length: 302\n",
      "DEBUG:root:Number of characters per captions: 167\n",
      "DEBUG:root:Number of characters per captions: 280\n",
      "DEBUG:root:Number of characters per captions: 311\n",
      "DEBUG:root:Number of characters per captions: 206\n",
      "DEBUG:root:Number of characters per captions: 302\n",
      "DEBUG:root:Number of characters per captions: 320\n",
      "DEBUG:root:Number of characters per captions: 267\n",
      "DEBUG:root:Number of characters per captions: 309\n",
      "DEBUG:root:Final Number of captions per image: 8\n",
      "DEBUG:root:New doc in Corpus Resizing Image Caption 5\n",
      "DEBUG:root:Finished - Maximizimizing number of captions per image\n",
      "INFO:root:MaximizeDocCaptions - Number of captions 24\n",
      "DEBUG:root:Ideal caption length: 84\n",
      "DEBUG:root:Number of characters per captions: 78\n",
      "DEBUG:root:Number of characters per captions: 79\n",
      "DEBUG:root:Number of characters per captions: 90\n",
      "DEBUG:root:Number of characters per captions: 88\n",
      "DEBUG:root:Number of characters per captions: 98\n",
      "DEBUG:root:Number of characters per captions: 69\n",
      "DEBUG:root:Number of characters per captions: 79\n",
      "DEBUG:root:Number of characters per captions: 75\n",
      "DEBUG:root:Final Number of captions per image: 8\n",
      "DEBUG:root:New doc in Corpus Resizing Image Caption 6\n",
      "DEBUG:root:Finished - Maximizimizing number of captions per image\n",
      "INFO:root:MaximizeDocCaptions - Number of captions 8\n",
      "DEBUG:root:Final Number of captions per image: 8\n"
     ]
    }
   ],
   "source": [
    "# 1.  Load zip file with two directories.  Image and text\n",
    "data_url = \"https://github.com/gryBox/pytig-data/raw/master/photosynthesis_raw.zip\"\n",
    "zipfile = lds.zip_from_url(data_url)\n",
    "\n",
    "# 2.  Write data: images and text to data directory\n",
    "# zipfile.extractall(data_path) Cant Find\n",
    "zipfile.extractall('data/')\n",
    "\n",
    "# 3.  Prepare text data for tig algorithms\n",
    "# Get txt files to process\n",
    "data_dir = os.path.join(os.path.abspath(''),\"data\")\n",
    "txt_dir = os.path.join(data_dir, 'photosynthesis_raw/text/')\n",
    "\n",
    "# # a. Load into corpus\n",
    "lbls_corpus = lds.image_labels_to_corpus(txt_dir)\n",
    "lbls_corpus\n",
    "\n",
    "# # b. Maximize the number of captions per image\n",
    "reshapedCaptions = idp.captions.ReshapeImageLabels(lbls_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'photosynthesis_4.txt': ['', '', '', '', '', '', '', ''],\n",
       " 'photosynthesis_0.txt': ['carbohydrates in living plants',\n",
       "  'plants from the carbon',\n",
       "  'water of the air',\n",
       "  'air under the influence',\n",
       "  'brought about by the action',\n",
       "  'formation of carbohydrates in living',\n",
       "  'living plants from the carbon',\n",
       "  'plants from the carbon di'],\n",
       " 'photosynthesis_5.txt': ['greek earth earth photosynthesis is a process process used by plants plants and other organisms',\n",
       "  'organisms to convert light light energy into chemical energy into chemical energy energy that can later',\n",
       "  'chemical energy is stored stored in carbohydrate molecules synthesized from carbon dioxide carbon dioxide and water',\n",
       "  'oxygen is also released released as a waste organisms are called photoautotrophs photosynthesis is largely responsible',\n",
       "  'largely responsible for producing maintaining the oxygen content content of the earth energy necessary for life',\n",
       "  'organisms to convert light energy convert light energy into chemical light energy into chemical energy',\n",
       "  'chemical energy that can later later be released to fuel released to fuel the organisms energy is stored in carbohydrate',\n",
       "  'released as a waste product responsible for producing and maintaining producing and maintaining the oxygen'],\n",
       " 'photosynthesis_6.txt': ['process in green plants green plants and certain',\n",
       "  'organisms by which carbohydrates',\n",
       "  'synthesized from carbon dioxide',\n",
       "  'carbon dioxide and water light as an energy',\n",
       "  'forms of photosynthesis release',\n",
       "  'oxygen as a byproduct',\n",
       "  'plants and certain other organisms',\n",
       "  'carbohydrates are synthesized from carbon'],\n",
       " 'photosynthesis_3.txt': ['photosynthesis is a process used by plants and other organisms to convert light energy into chemical energy that can later be released to fuel the organisms activities',\n",
       "  'this chemical energy is stored in carbohydrate molecules such as sugars which are synthesized from carbon dioxide and water hence the name photosynthesis from the greek φῶς phōs light and σύνθεσις synthesis putting together in most cases oxygen is also released as a waste product',\n",
       "  'most plants most algae and cyanobacteria perform photosynthesis such organisms are called photoautotrophs photosynthesis is largely responsible for producing and maintaining the oxygen content of the earth s atmosphere and supplies all of the organic compounds and most of the energy necessary for life on earth',\n",
       "  'although photosynthesis is performed differently by different species the process always begins when energy from light is absorbed by proteins called reaction centres that contain green chlorophyll pigments',\n",
       "  'in plants these proteins are held inside organelles called chloroplasts which are most abundant in leaf cells while in bacteria they are embedded in the plasma membrane in these light dependent reactions some energy is used to strip electrons from suitable substances such as water producing oxygen gas',\n",
       "  'the hydrogen freed by the splitting of water is used in the creation of two further compounds that serve as short term stores of energy enabling its transfer to drive other reactions these compounds are reduced nicotinamide adenine dinucleotide phosphate nadph and adenosine triphosphate atp the energy currency of cells',\n",
       "  'in plants algae and cyanobacteria long term energy storage in the form of sugars is produced by a subsequent sequence of light independent reactions called the calvin cycle some bacteria use different mechanisms such as the reverse krebs cycle to achieve the same end',\n",
       "  'in the calvin cycle atmospheric carbon dioxide is incorporated into already existing organic carbon compounds such as ribulose bisphosphate rubp using the atp and nadph produced by the light dependent reactions the resulting compounds are then reduced and removed to form further carbohydrates such as glucose'],\n",
       " 'photosynthesis_1.txt': ['process by which green use sunlight to synthesize sunlight to synthesize foods',\n",
       "  'synthesize foods from carbon foods from carbon dioxide carbon dioxide and water',\n",
       "  'photosynthesis in plants generally generally involves the green involves the green pigment',\n",
       "  'pigment chlorophyll and generates chlorophyll and generates oxygen oxygen as a byproduct',\n",
       "  'process by which green plants plants and some other organisms organisms use sunlight to synthesize',\n",
       "  'use sunlight to synthesize foods synthesize foods from carbon dioxide',\n",
       "  'photosynthesis in plants generally involves plants generally involves the green',\n",
       "  'generally involves the green pigment involves the green pigment chlorophyll'],\n",
       " 'photosynthesis_2.txt': ['process by which plants',\n",
       "  'plants and other photoautotrophs',\n",
       "  'generate carbohydrates and oxygen',\n",
       "  'oxygen from carbon dioxide',\n",
       "  'light energy in chloroplasts',\n",
       "  'plants and other photoautotrophs generate',\n",
       "  'photoautotrophs generate carbohydrates and oxygen',\n",
       "  'carbohydrates and oxygen from carbon']}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshapedCaptions.captions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_corpus(df):\n",
    "    # Load into textacy to delimit sentences\n",
    "    img_labels = rsrc_df.to_dict(orient=\"records\")\n",
    "    records = textacy.io.split_records(img_labels, 'RESOURCE',itemwise=True)\n",
    "\n",
    "    # Load english model\n",
    "    en = en_core_web_sm.load()\n",
    "    corpus = textacy.Corpus(lang=en, data=records)\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captionsCorpus = df_to_corpus(rsrc_df)\n",
    "captionsCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in captionsCorpus:\n",
    "    print(doc._.preview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Write new image text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Labels for text to image model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_directories(directory_flpth):\n",
    "    # Handle missing Directory\n",
    "    if not os.path.exists(directory_flpth):\n",
    "        \n",
    "        os.makedirs(directory_flpth)\n",
    "        print(\"Made new directory: {}\".format(directory_flpth))\n",
    "        # print(os.path.join(dirname, flpth))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return\n",
    "\n",
    "# Create text file for each doc - Each Doc maps to an image\n",
    "\n",
    "## TODO: incoroporate number of labals per line\n",
    "def labels_to_imageTxt_files(rsrc_df, trainingData_term, trainigData_flpth='../data'):\n",
    "    \n",
    "    # Handle if a data directory for a term exists e.g. data/photosynthesis\n",
    "    dirname = os.path.abspath('')\n",
    "    termData_flpth = os.path.join(dirname, trainigData_flpth)\n",
    "    handle_missing_directories(termData_flpth)\n",
    "    \n",
    "    \n",
    "    ### Move resource df to textacy\n",
    "   \n",
    "    # Load into textacy to delimit sentences\n",
    "    img_labels = rsrc_df.to_dict(orient=\"records\")\n",
    "    text_stream, metadata_stream = textacy.io.split_records(img_labels, 'RESOURCE')\n",
    "\n",
    "    # Load english model\n",
    "    en = en_core_web_sm.load()\n",
    "    labels_corpus = textacy.Corpus(lang=en, texts=text_stream, metadatas=metadata_stream)\n",
    "    \n",
    "    caption_filename_path = os.path.join(trainigData_flpth, \"captions.pickle\")\n",
    "    \n",
    "    # Loop through corpus and write document to flpth (s3)\n",
    "    ''' Each doc in a corpus equals and image'''\n",
    "    for ix, doc in enumerate(labels_corpus):\n",
    "        print(\"Number of Sentences: {}\".format(doc.n_sents))\n",
    "        \n",
    "        # Paths to directories (Where to write the text files)\n",
    "        filename = \"{}_{}.txt\".format(trainingData_term, ix)\n",
    "        path_to_file = \"{}/{}\".format(trainigData_flpth, filename)\n",
    "        \n",
    "        # Write captions for google images\n",
    "        f =  open(path_to_file, 'w')\n",
    "        \n",
    "        # Parse Document into sentences\n",
    "        for sent in doc.sents:\n",
    "            caption = textacy.preprocess.preprocess_text(sent.text,\n",
    "                                               lowercase=True,\n",
    "                                               no_punct=True\n",
    "                                              )\n",
    "            # f.write(label+\"\\n\" )\n",
    "            f.write(caption+\" \" )\n",
    "            \n",
    "        f.close()\n",
    "        \n",
    "    return ix + 1 # Count using 1 as start\n",
    "\n",
    "# process labels for images\n",
    "\n",
    "\n",
    "trainingData_term = 'photosynthesis'\n",
    "txt_trainingData_flpth='{}/text'.format(termTxtToImage_flpth, 'text')\n",
    "\n",
    "numText_files = labels_to_imageTxt_files(rsrc_df, trainingData_term, txt_trainingData_flpth)\n",
    "numText_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Images from google "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_images(term ,img_args):\n",
    "    \n",
    "    # Download Images \n",
    "    response = google_images_download.googleimagesdownload()\n",
    "    img_paths = response.download(img_args)\n",
    "    \n",
    "    # Post Process google image results\n",
    "    for idx, f in enumerate(img_paths[term]):\n",
    "        \n",
    "        # Open Google image resulst and conver to jpeg\n",
    "        img = PIL.Image.open(f)\n",
    "        img_filetype = img.format.lower()  # 'JPEG'\n",
    "        \n",
    "        rgb_img = img.convert('RGB')\n",
    "        img.close()\n",
    "        \n",
    "        # Make new filenme to allign with text file name\n",
    "        filename = \"{}_{}.{}\".format(trainingData_term, idx, 'jpg')\n",
    "        newfilepath_f = os.path.join(os.path.dirname(f), filename)\n",
    "        \n",
    "        # Save and image\n",
    "        rgb_img.save(newfilepath_f)\n",
    "        os.remove(f)\n",
    "    \n",
    "    \n",
    "    return response \n",
    "\n",
    "img_args = {\"keywords\":\"sun\",\n",
    "             \"format\": \"png\",\n",
    "              \"limit\": 20,\n",
    "             \"output_directory\": 'data',\n",
    "            \"metadata\": True,\n",
    "            \"image_directory\": \"photosynthesis/images\",\n",
    "            \"no_download\": False,\n",
    "            \"extract_metadata\":True\n",
    "            # \"size\":\"icon\"\n",
    "           }\n",
    "\n",
    "response = download_images(trainingData_term, img_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tigDataLoader.utiils as dataloader\n",
    "import os\n",
    "import json\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictTerm = \"photosynthesis\"\n",
    "dataTerm = \"photosynthesis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base file io inputs\n",
    "trainData_flpth = os.path.join('data', predictTerm)\n",
    "text_flpth = os.path.join(trainData_flpth, 'text')\n",
    "img_flpth =  os.path.join(trainData_flpth, 'images')\n",
    "\n",
    "# Google imagae download metadata\n",
    "imageLog_fir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText_to_captions(txtDoc, numCaptions_per_image=5, txtSplit_method='svo'):\n",
    "    # Take textacy doc and converts to a list of captions for an image\n",
    "    \n",
    "    if txtSplit_method=='noun_chunks':\n",
    "        split_list = list(textacy.extract.noun_chunks(txtDoc, drop_determiners=False, min_freq=1))\n",
    "    if txtSplit_method=='svo':\n",
    "        split_list = list(textacy.extract.subject_verb_object_triples(txtDoc))\n",
    "    \n",
    "    return split_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Download images\n",
    "- from google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_args = {\"keywords\": dataTerm,\n",
    "             \"format\": \"png\",\n",
    "              \"limit\": 100,\n",
    "             \"output_directory\": 'data',\n",
    "            \"metadata\": True,\n",
    "            \"image_directory\": \"{}/images/\".format(predictTerm),\n",
    "            \"no_download\": False,\n",
    "            \"extract_metadata\":True,\n",
    "            \"type\": \"clipart\"\n",
    "           }\n",
    "img_paths, response = dataloader.download_images(dataTerm, img_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download text from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load text into textacy\n",
    "imgTxt_corpus = df_to_corpus()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(labels_corpus.docs[0].sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get(\"https://ssec.si.edu/stemvisions-blog/what-photosynthesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Fake data\n",
    "import shutil\n",
    "import itertools\n",
    "\n",
    "# Get a list of the original files f\n",
    "txtDirFileNm_lst = glob.glob(text_flpth+\"/**/*.txt\", recursive=True)\n",
    "imgDirFileNm_lst = glob.glob(img_flpth+\"/**/*.jpg\", recursive=True)\n",
    "\n",
    "fileCombo_lst = list(itertools.product(txtDirFileNm_lst,imgDirFileNm_lst))\n",
    "\n",
    "# for item in fileCombo_lst:\n",
    "    \n",
    "#     # Get text name\n",
    "#     txtget_relfilename\n",
    "\n",
    "# # # Create list paired tuple pairs\n",
    "# # comboFlpth_lst = list(zip(txtDirFileNm_lst, imgDirFileNm_lst))\n",
    "# # comboFlpth_lst\n",
    "\n",
    "# # new_list = []\n",
    "# # for k,v in comboFlpth_lst.iteritems():\n",
    "# #     new_list.extend([x for x in combinations(v, 2)]) \n",
    "# # # for txtFile, imgFile in comboFlpth_dict:\n",
    "# # #     # Make copies of files and rename\n",
    "# # #     shutil.copyfile(txtFile, dst)\n",
    "# # #     shutil.copyfile(imgFile, dst)\n",
    "\n",
    "# # new_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df = pd.read_csv(\"RUNS.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"s_loss\", y=\"embedding_dim\", data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_algorithm(captions_df['n_chars'].tolist(), ideal_caption_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_algorithm(captions_df['n_chars'].tolist(), ideal_caption_length)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'synthesis of compounds with the aid of radiant energy (especially in plants)'\n",
    "\n",
    "synthesis=noun\n",
    "of = preposition\n",
    "compound = phrase of prepostion (noun)\n",
    "with = preposition\n",
    "the = difinite article\n",
    "aid = noun\n",
    "of = preposition\n",
    "radiant = adj epithet (the adjective that describes the noun)\n",
    "energy = noun\n",
    "with the aid of radiant energy is the phrase of the preposition\n",
    "especcially = asverb\n",
    "in = preposition\n",
    "plamts is a noun+\n",
    "\n",
    "[[('synthesis', 'NOUN'),\n",
    "  ('of', 'ADP'),\n",
    "  ('compounds', 'NOUN'),\n",
    "  ('with', 'ADP'),\n",
    "  ('the', 'DET'),\n",
    "  ('aid', 'NOUN'),\n",
    "  ('of', 'ADP'),\n",
    "  ('radiant', 'ADJ'),\n",
    "  ('energy', 'NOUN'),\n",
    "  ('(', 'PUNCT'),\n",
    "  ('especially', 'ADV'),\n",
    "  ('in', 'ADP'),\n",
    "  ('plants', 'NOUN'),\n",
    "  (')', 'PUNCT')]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load text from s3 to df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inputTerm_lst = ['photosynthesis', 'sun', 'water']\n",
    "\n",
    "inputTerm_df_lst = []\n",
    "for inputTerm in inputTerm_lst:\n",
    "    nodeIdentifierName = \"{}-{}-{}-{}\".format(inputTerm, inputTerm, inputTerm, topic)\n",
    "    s3key = \"NODE-DATASTORE-TMP/{}/normedFedSearch.json\".format(nodeIdentifierName)\n",
    "    s3 = boto3.client('s3')\n",
    "    result = s3.get_object(Bucket='egm-bucket', Key=s3key)\n",
    "    file_content = result['Body'].read().decode('utf-8')\n",
    "    json_content = json.loads(file_content)\n",
    "    df = pd.DataFrame(json_content)\n",
    "    inputTerm_df_lst.append(df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "captions_df = pd.concat(inputTerm_df_lst)\n",
    "captions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-ml",
   "language": "python",
   "name": "py36-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
