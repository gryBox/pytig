{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%load_ext autotime\n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "import boto3\n",
    "from boto3.dynamodb.conditions import Key\n",
    "import os\n",
    "import PIL\n",
    "import json\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pickle\n",
    "import dask\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import textacy\n",
    "import en_core_web_sm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# from custo import greedy_algorithm\n",
    "#import input_data_preprocessing.corpus_stats as c_stats\n",
    "\n",
    "textacy.spacier.doc_extensions.set_doc_extensions()\n",
    "en = en_core_web_sm.load()\n",
    "#import code\n",
    "print(textacy.__version__)\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TIG Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "import pytig as ptg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_dir_name = 'data'\n",
    "\n",
    "metadata_folder_name = 'photosynthesis_raw'\n",
    "txt_dir_flname =  \"text\"\n",
    "img_dir_flname =  'images'\n",
    "\n",
    "    \n",
    "zip_url = f\"https://github.com/gryBox/pytig-data/raw/master/{metadata_folder_name}.zip\"\n",
    "data_dir_flpth = os.path.abspath(data_dir_name)\n",
    "print(data_dir_flpth)\n",
    "\n",
    "metadata_flpth = os.path.join(data_dir_flpth, metadata_folder_name)\n",
    "print(metadata_flpth)\n",
    "\n",
    "text_data_flpth = os.path.join(metadata_flpth, txt_dir_flname)\n",
    "image_data_flpth = os.path.join(metadata_flpth, img_dir_flname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "# 1. Load training data for algorithm (Needs to be done even if only using predict)\n",
    "zipfile = ptg.write.zip_to_metadata_dir(zip_url, data_dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Metadata Folder for AttnGAN\n",
    "- Normalize Filenames\n",
    "- Create basename file\n",
    "- Pickle Files\n",
    "- Sample caption files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare MetaData folder for attngan model\n",
    "\n",
    "\n",
    "# 1.  Prepare Filenames\n",
    "# a. Extract basenames\n",
    "prpFilenames = ptg.filenames.PrepareFilenames(metadata_flpth, \n",
    "                                                   image_data_flpth, \n",
    "                                                   text_data_flpth, \n",
    "                                                   )\n",
    "# b. Write new filenames back to disk using the new filenames and updates the fileNames_df \n",
    "prpFilenames.rename_filenames()\n",
    "    \n",
    "# c. Write basenames to a \".txt\" file in the metadata folder\n",
    "prpFilenames.basenames_to_txtfile(basename_flname='filenames.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prpFilenames.fileNames_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaFolder = ptg.prepare_metadata_dir.Metadata(metadata_flpth, image_data_flpth, text_data_flpth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames, test_filenames = metaFolder.split_data(prpFilenames.fileNames_df, \n",
    "                                                        test_size=0.3,  \n",
    "                                                        filenames_clm=prpFilenames.basenameCol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Captions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### photosynthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load text captions to corpus\n",
    "captCrps = ptg.write.txt_to_corpus(text_data_flpth, lang=en, txt_extention=\".txt\")\n",
    "print(f\"\\nCorpus Info: {captCrps}\")\n",
    "\n",
    "# 2. Preview some docs\n",
    "example_doc = 5\n",
    "cap_doc = captCrps[example_doc]\n",
    "print(f\"\\nNumber of sentences: {cap_doc._.n_sents}\")\n",
    "print(f\"Text: {cap_doc.text}\\n\")\n",
    "\n",
    "display(captCrps.docstats_df.iloc[example_doc].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir_nm = 'AttnGAN'\n",
    "data_dir_nm = 'data'\n",
    "metadata_dir_nm ='birds'\n",
    "\n",
    "metadata_flpth = os.path.join(\"/home/ec2-user/environment/\", root_dir_nm, data_dir_nm, metadata_dir_nm)\n",
    "metadata_flpth\n",
    "\n",
    "btxt_dir_flpth = os.path.join(metadata_flpth, 'text')\n",
    "print(btxt_dir_flpth)\n",
    "print(os.path.exists(btxt_dir_flpth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load text captions to corpus\n",
    "birdsCrps = ptg.write.txt_to_corpus(btxt_dir_flpth, lang=en, txt_extention=\".txt\")\n",
    "print(f\"\\nCorpus Info: {captCrps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir_nm = 'AttnGAN'\n",
    "data_dir_nm = 'data'\n",
    "metadata_dir_nm ='coco'\n",
    "\n",
    "metadata_flpth = os.path.join(\"/home/ec2-user/environment/\", root_dir_nm, data_dir_nm, metadata_dir_nm)\n",
    "metadata_flpth\n",
    "\n",
    "coco_txt_dir_flpth = os.path.join(metadata_flpth, 'text')\n",
    "print(btxt_dir_flpth)\n",
    "print(os.path.exists(btxt_dir_flpth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load text captions to corpus\n",
    "cocoCrps = ptg.write.txt_to_corpus(coco_txt_dir_flpth, lang=en, txt_extention=\".txt\")\n",
    "print(f\"\\nCorpus Info: {captCrps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook, show\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the rest of the tutorial, we assume that the `plt`\n",
    "# is imported before every code snippet.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from chainercv.datasets import voc_bbox_label_names\n",
    "from chainercv.links import SSD300\n",
    "from chainercv.utils import read_image\n",
    "from chainercv.visualizations import vis_bbox\n",
    "\n",
    "img_name = \"photosynthesis_0.jpg\"\n",
    "img_flpth = os.path.join(image_data_flpth, img_name)\n",
    "\n",
    "# Read an RGB image and return it in CHW format.\n",
    "img = read_image(img_flpth)\n",
    "model = SSD300(pretrained_model='voc0712')\n",
    "bboxes, labels, scores = model.predict([img])\n",
    "vis_bbox(img, bboxes[0], labels[0], scores[0],\n",
    "         label_names=voc_bbox_label_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(metaFolder.metadata_flpth, 'train', \"filenames.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df[\"filename\"], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " os.path.basename(metaFolder.metadata_flpth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sents_to_caption_lst(doc):\n",
    "    \"\"\"\n",
    "    Split doc text by sentences and write to list\n",
    "    \"\"\"\n",
    "    doc_captions_lst = [sent.text for sent in doc.sents]\n",
    "\n",
    "    \n",
    "    return doc_captions_lst\n",
    "\n",
    "\n",
    "# 2. Modify training text data. i.e lowercase, ##maximize captions\n",
    "\n",
    "# # 2.1  Read text data into a spacy corpus using textacy\n",
    "crps = pmd.write.txt_to_corpus(text_training_data_flpth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_captions_lst = sents_to_caption_lst(doc)\n",
    "doc_captions_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc._.meta[crps_file_tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tst_doc.text\n",
    "\n",
    "def write_doc_to_txt(doc, crps_file_tag=\"file_name\"):\n",
    "\n",
    "    # Write captions for google images\n",
    "    f =  open(doc._.meta[crps_file_tag], 'w')\n",
    "    print(f\"Number of Sentences in doc: {doc._.n_sents}\")\n",
    "    \n",
    "    # Parse Document into sentences\n",
    "    \n",
    "        # f.write(label+\"\\n\" )\n",
    "        f.write(caption+\" \" )\n",
    "\n",
    "    f.close()\n",
    "write_doc_to_txt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in crps:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.path.expanduser(\"~\"), 'imageGen/AttnGAN/data/')\n",
    "print(os.path.exists(data_path))\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # b. Maximize the number of captions per image\n",
    "reshapedCaptions = idp.captions.ReshapeImageLabels(lbls_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshapedCaptions.captions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_corpus(df):\n",
    "    # Load into textacy to delimit sentences\n",
    "    img_labels = rsrc_df.to_dict(orient=\"records\")\n",
    "    records = textacy.io.split_records(img_labels, 'RESOURCE',itemwise=True)\n",
    "\n",
    "    # Load english model\n",
    "    en = en_core_web_sm.load()\n",
    "    corpus = textacy.Corpus(lang=en, data=records)\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captionsCorpus = df_to_corpus(rsrc_df)\n",
    "captionsCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in captionsCorpus:\n",
    "    print(doc._.preview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Write new image text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Labels for text to image model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_directories(directory_flpth):\n",
    "    # Handle missing Directory\n",
    "    if not os.path.exists(directory_flpth):\n",
    "        \n",
    "        os.makedirs(directory_flpth)\n",
    "        print(\"Made new directory: {}\".format(directory_flpth))\n",
    "        # print(os.path.join(dirname, flpth))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return\n",
    "\n",
    "# Create text file for each doc - Each Doc maps to an image\n",
    "\n",
    "## TODO: incoroporate number of labals per line\n",
    "def labels_to_imageTxt_files(rsrc_df, trainingData_term, trainigData_flpth='../data'):\n",
    "    \n",
    "    # Handle if a data directory for a term exists e.g. data/photosynthesis\n",
    "    dirname = os.path.abspath('')\n",
    "    termData_flpth = os.path.join(dirname, trainigData_flpth)\n",
    "    handle_missing_directories(termData_flpth)\n",
    "    \n",
    "    \n",
    "    ### Move resource df to textacy\n",
    "   \n",
    "    # Load into textacy to delimit sentences\n",
    "    img_labels = rsrc_df.to_dict(orient=\"records\")\n",
    "    text_stream, metadata_stream = textacy.io.split_records(img_labels, 'RESOURCE')\n",
    "\n",
    "    # Load english model\n",
    "    en = en_core_web_sm.load()\n",
    "    labels_corpus = textacy.Corpus(lang=en, texts=text_stream, metadatas=metadata_stream)\n",
    "    \n",
    "    caption_filename_path = os.path.join(trainigData_flpth, \"captions.pickle\")\n",
    "    \n",
    "    # Loop through corpus and write document to flpth (s3)\n",
    "    ''' Each doc in a corpus equals and image'''\n",
    "    for ix, doc in enumerate(labels_corpus):\n",
    "        print(\"Number of Sentences: {}\".format(doc.n_sents))\n",
    "        \n",
    "        # Paths to directories (Where to write the text files)\n",
    "        filename = \"{}_{}.txt\".format(trainingData_term, ix)\n",
    "        path_to_file = \"{}/{}\".format(trainigData_flpth, filename)\n",
    "        \n",
    "        # Write captions for google images\n",
    "        f =  open(path_to_file, 'w')\n",
    "        \n",
    "        # Parse Document into sentences\n",
    "        for sent in doc.sents:\n",
    "            caption = textacy.preprocess.preprocess_text(sent.text,\n",
    "                                               lowercase=True,\n",
    "                                               no_punct=True\n",
    "                                              )\n",
    "            # f.write(label+\"\\n\" )\n",
    "            f.write(caption+\" \" )\n",
    "            \n",
    "        f.close()\n",
    "        \n",
    "    return ix + 1 # Count using 1 as start\n",
    "\n",
    "# process labels for images\n",
    "\n",
    "\n",
    "trainingData_term = 'photosynthesis'\n",
    "txt_trainingData_flpth='{}/text'.format(termTxtToImage_flpth, 'text')\n",
    "\n",
    "numText_files = labels_to_imageTxt_files(rsrc_df, trainingData_term, txt_trainingData_flpth)\n",
    "numText_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Images from google "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_images(term ,img_args):\n",
    "    \n",
    "    # Download Images \n",
    "    response = google_images_download.googleimagesdownload()\n",
    "    img_paths = response.download(img_args)\n",
    "    \n",
    "    # Post Process google image results\n",
    "    for idx, f in enumerate(img_paths[term]):\n",
    "        \n",
    "        # Open Google image resulst and conver to jpeg\n",
    "        img = PIL.Image.open(f)\n",
    "        img_filetype = img.format.lower()  # 'JPEG'\n",
    "        \n",
    "        rgb_img = img.convert('RGB')\n",
    "        img.close()\n",
    "        \n",
    "        # Make new filenme to allign with text file name\n",
    "        filename = \"{}_{}.{}\".format(trainingData_term, idx, 'jpg')\n",
    "        newfilepath_f = os.path.join(os.path.dirname(f), filename)\n",
    "        \n",
    "        # Save and image\n",
    "        rgb_img.save(newfilepath_f)\n",
    "        os.remove(f)\n",
    "    \n",
    "    \n",
    "    return response \n",
    "\n",
    "img_args = {\"keywords\":\"sun\",\n",
    "             \"format\": \"png\",\n",
    "              \"limit\": 20,\n",
    "             \"output_directory\": 'data',\n",
    "            \"metadata\": True,\n",
    "            \"image_directory\": \"photosynthesis/images\",\n",
    "            \"no_download\": False,\n",
    "            \"extract_metadata\":True\n",
    "            # \"size\":\"icon\"\n",
    "           }\n",
    "\n",
    "response = download_images(trainingData_term, img_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tigDataLoader.utiils as dataloader\n",
    "import os\n",
    "import json\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictTerm = \"photosynthesis\"\n",
    "dataTerm = \"photosynthesis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base file io inputs\n",
    "trainData_flpth = os.path.join('data', predictTerm)\n",
    "text_flpth = os.path.join(trainData_flpth, 'text')\n",
    "img_flpth =  os.path.join(trainData_flpth, 'images')\n",
    "\n",
    "# Google imagae download metadata\n",
    "imageLog_fir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText_to_captions(txtDoc, numCaptions_per_image=5, txtSplit_method='svo'):\n",
    "    # Take textacy doc and converts to a list of captions for an image\n",
    "    \n",
    "    if txtSplit_method=='noun_chunks':\n",
    "        split_list = list(textacy.extract.noun_chunks(txtDoc, drop_determiners=False, min_freq=1))\n",
    "    if txtSplit_method=='svo':\n",
    "        split_list = list(textacy.extract.subject_verb_object_triples(txtDoc))\n",
    "    \n",
    "    return split_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Download images\n",
    "- from google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_args = {\"keywords\": dataTerm,\n",
    "             \"format\": \"png\",\n",
    "              \"limit\": 100,\n",
    "             \"output_directory\": 'data',\n",
    "            \"metadata\": True,\n",
    "            \"image_directory\": \"{}/images/\".format(predictTerm),\n",
    "            \"no_download\": False,\n",
    "            \"extract_metadata\":True,\n",
    "            \"type\": \"clipart\"\n",
    "           }\n",
    "img_paths, response = dataloader.download_images(dataTerm, img_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download text from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load text into textacy\n",
    "imgTxt_corpus = df_to_corpus()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(labels_corpus.docs[0].sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get(\"https://ssec.si.edu/stemvisions-blog/what-photosynthesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Fake data\n",
    "import shutil\n",
    "import itertools\n",
    "\n",
    "# Get a list of the original files f\n",
    "txtDirFileNm_lst = glob.glob(text_flpth+\"/**/*.txt\", recursive=True)\n",
    "imgDirFileNm_lst = glob.glob(img_flpth+\"/**/*.jpg\", recursive=True)\n",
    "\n",
    "fileCombo_lst = list(itertools.product(txtDirFileNm_lst,imgDirFileNm_lst))\n",
    "\n",
    "# for item in fileCombo_lst:\n",
    "    \n",
    "#     # Get text name\n",
    "#     txtget_relfilename\n",
    "\n",
    "# # # Create list paired tuple pairs\n",
    "# # comboFlpth_lst = list(zip(txtDirFileNm_lst, imgDirFileNm_lst))\n",
    "# # comboFlpth_lst\n",
    "\n",
    "# # new_list = []\n",
    "# # for k,v in comboFlpth_lst.iteritems():\n",
    "# #     new_list.extend([x for x in combinations(v, 2)]) \n",
    "# # # for txtFile, imgFile in comboFlpth_dict:\n",
    "# # #     # Make copies of files and rename\n",
    "# # #     shutil.copyfile(txtFile, dst)\n",
    "# # #     shutil.copyfile(imgFile, dst)\n",
    "\n",
    "# # new_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df = pd.read_csv(\"RUNS.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"s_loss\", y=\"embedding_dim\", data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_algorithm(captions_df['n_chars'].tolist(), ideal_caption_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_algorithm(captions_df['n_chars'].tolist(), ideal_caption_length)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'synthesis of compounds with the aid of radiant energy (especially in plants)'\n",
    "\n",
    "synthesis=noun\n",
    "of = preposition\n",
    "compound = phrase of prepostion (noun)\n",
    "with = preposition\n",
    "the = difinite article\n",
    "aid = noun\n",
    "of = preposition\n",
    "radiant = adj epithet (the adjective that describes the noun)\n",
    "energy = noun\n",
    "with the aid of radiant energy is the phrase of the preposition\n",
    "especcially = asverb\n",
    "in = preposition\n",
    "plamts is a noun+\n",
    "\n",
    "[[('synthesis', 'NOUN'),\n",
    "  ('of', 'ADP'),\n",
    "  ('compounds', 'NOUN'),\n",
    "  ('with', 'ADP'),\n",
    "  ('the', 'DET'),\n",
    "  ('aid', 'NOUN'),\n",
    "  ('of', 'ADP'),\n",
    "  ('radiant', 'ADJ'),\n",
    "  ('energy', 'NOUN'),\n",
    "  ('(', 'PUNCT'),\n",
    "  ('especially', 'ADV'),\n",
    "  ('in', 'ADP'),\n",
    "  ('plants', 'NOUN'),\n",
    "  (')', 'PUNCT')]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load text from s3 to df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inputTerm_lst = ['photosynthesis', 'sun', 'water']\n",
    "\n",
    "inputTerm_df_lst = []\n",
    "for inputTerm in inputTerm_lst:\n",
    "    nodeIdentifierName = \"{}-{}-{}-{}\".format(inputTerm, inputTerm, inputTerm, topic)\n",
    "    s3key = \"NODE-DATASTORE-TMP/{}/normedFedSearch.json\".format(nodeIdentifierName)\n",
    "    s3 = boto3.client('s3')\n",
    "    result = s3.get_object(Bucket='egm-bucket', Key=s3key)\n",
    "    file_content = result['Body'].read().decode('utf-8')\n",
    "    json_content = json.loads(file_content)\n",
    "    df = pd.DataFrame(json_content)\n",
    "    inputTerm_df_lst.append(df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "captions_df = pd.concat(inputTerm_df_lst)\n",
    "captions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-ml",
   "language": "python",
   "name": "py36-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
